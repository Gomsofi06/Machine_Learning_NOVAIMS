{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Project</center>\n",
    "\n",
    "** **\n",
    "## <center>*04.1 - CatBoosted*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "The members of the `team` are:\n",
    "- Ana Farinha - 20211514\n",
    "- Francisco Capontes - 20211692\n",
    "- Sofia Gomes - 20240848\n",
    "- Rui Louren√ßo - 2021639\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#make the split here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "from utils_feature_selection import check_performace\n",
    "from utils_dicts import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_state=68+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:salmon\"> 1. Import Dataset </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train_df = pd.read_csv('preprocessed_data/train_data.csv', index_col=\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "test_df = pd.read_csv('./preprocessed_data/test_data.csv', index_col = 'Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Selection: essential_features, reduced_features or [] (No Feature Selection)\n",
    "feature_selection = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define y as a target \"Claim Injury Type Encoded\" and X with all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop([\"Claim Injury Type Encoded\"], axis = 1)\n",
    "y = train_df[\"Claim Injury Type Encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:salmon\"> 2. CatBoosted </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:salmon\"> 2.1  Model K-fold cross validation </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_1 ={\n",
    "        \"iterations\": 300,\n",
    "        \"learning_rate\": 0.7,\n",
    "        \"depth\": 6,\n",
    "        \"l2_leaf_reg\": 6,\n",
    "        \"bagging_temperature\": 0.7,\n",
    "        \"random_state\": random_state\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "        iterations=config_1[\"iterations\"],\n",
    "        learning_rate=config_1[\"learning_rate\"],\n",
    "        depth=config_1[\"depth\"],\n",
    "        l2_leaf_reg=config_1[\"l2_leaf_reg\"],\n",
    "        bagging_temperature=config_1[\"bagging_temperature\"],\n",
    "        # -------------------\n",
    "        random_state = config_1[\"random_state\"],\n",
    "        custom_metric='F1', \n",
    "        early_stopping_rounds=50,\n",
    "        verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 train F1 score: 0.3720\n",
      "Fold 1 validation F1 score: 0.3107\n",
      "------------------------------\n",
      "Fold 2 train F1 score: 0.3678\n",
      "Fold 2 validation F1 score: 0.3192\n",
      "------------------------------\n",
      "Fold 3 train F1 score: 0.3651\n",
      "Fold 3 validation F1 score: 0.3149\n",
      "------------------------------\n",
      "Average Train F1 score: 0.3682958001583308\n",
      "Average Validation F1 score: 0.3149497495591473\n"
     ]
    }
   ],
   "source": [
    "check_performace(model,X,y,numerical_features,essential_features,n_folds = 3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The use of the Reduced Features made the model worse than no feature selection or only the essential features\n",
    "#check_performace(model,X,y,numerical_features,reduced_features,n_folds = 3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_2 ={\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": 0.11,\n",
    "        \"depth\": 6,\n",
    "        \"l2_leaf_reg\": 5,\n",
    "        \"bagging_temperature\": 0.4,\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "        iterations=config_2[\"iterations\"],\n",
    "        learning_rate=config_2[\"learning_rate\"],\n",
    "        depth=config_2[\"depth\"],\n",
    "        l2_leaf_reg=config_2[\"l2_leaf_reg\"],\n",
    "        bagging_temperature=config_2[\"bagging_temperature\"],\n",
    "        # -------------------\n",
    "        random_state = config_2[\"random_state\"],\n",
    "        custom_metric='F1', \n",
    "        early_stopping_rounds=50,\n",
    "        verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 train F1 score: 0.5592\n",
      "Fold 1 validation F1 score: 0.4140\n",
      "------------------------------\n",
      "Fold 2 train F1 score: 0.5660\n",
      "Fold 2 validation F1 score: 0.4141\n",
      "------------------------------\n",
      "Fold 3 train F1 score: 0.5608\n",
      "Fold 3 validation F1 score: 0.4046\n",
      "------------------------------\n",
      "Average Train F1 score: 0.5619988502534625\n",
      "Average Validation F1 score: 0.41089690988965594\n"
     ]
    }
   ],
   "source": [
    "check_performace(model,X,y,numerical_features,[],n_folds = 3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:salmon\"> 2.2  Train the model </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_config = config_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "        iterations=selected_config[\"iterations\"],\n",
    "        learning_rate=selected_config[\"learning_rate\"],\n",
    "        depth=selected_config[\"depth\"],\n",
    "        l2_leaf_reg=selected_config[\"l2_leaf_reg\"],\n",
    "        bagging_temperature=selected_config[\"bagging_temperature\"],\n",
    "        # -------------------\n",
    "        random_state = selected_config[\"random_state\"],\n",
    "        custom_metric='F1', \n",
    "        early_stopping_rounds=50,\n",
    "        verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.20, stratify = y, shuffle = True, random_state=random_state)\n",
    "X_train_to_preprocess=X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers(X_train)\n",
    "X_train, X_val = apply_frequency_encoding(X_train, X_val)\n",
    "NA_imputer(X_train,X_val)\n",
    "create_new_features(X_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train[numerical_features])\n",
    "X_train[numerical_features]  = scaler.transform(X_train[numerical_features])\n",
    "X_val[numerical_features]  = scaler.transform(X_val[numerical_features])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\"Average Weekly Wage\"]\n",
    "if feature_selection != []:\n",
    "    for col in X_train.columns:\n",
    "        if col not in feature_selection:\n",
    "            drop_list.append(col)\n",
    "X_train = X_train.drop(drop_list, axis=1)\n",
    "X_val = X_val.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x16e19ec17d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:salmon\"> 2.3  Model Results </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0:'1. CANCELLED', \n",
    "    1:'2. NON-COMP',\n",
    "    2:'3. MED ONLY', \n",
    "    3:'4. TEMPORARY',\n",
    "    4:'5. PPD SCH LOSS', \n",
    "    5:'6. PPD NSL', \n",
    "    6:'7. PTD', \n",
    "    7:'8. DEATH'\n",
    "}\n",
    "\n",
    "# Use the values from class_mapping as the target names\n",
    "target_names = list(class_mapping.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute confusion matrix to evaluate the accuracy of a classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  5168   4115    150    515     29      0      0      3]\n",
      " [  1446 224008   1106   5887    406      0      0      9]\n",
      " [    55  31721   5312  15564   2465      1      0      7]\n",
      " [    65  26688   2194  83590   6240      2      0     26]\n",
      " [     4   1341    600  13053  23624      2      0      0]\n",
      " [     0      8     34   2848    429     50      0      0]\n",
      " [     0      0      0     52      2      0     24      0]\n",
      " [     2     25      4     78      2      0      0    265]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   1. CANCELLED       0.77      0.52      0.62      9980\n",
      "    2. NON-COMP       0.78      0.96      0.86    232862\n",
      "    3. MED ONLY       0.57      0.10      0.16     55125\n",
      "   4. TEMPORARY       0.69      0.70      0.70    118805\n",
      "5. PPD SCH LOSS       0.71      0.61      0.66     38624\n",
      "     6. PPD NSL       0.91      0.01      0.03      3369\n",
      "         7. PTD       1.00      0.31      0.47        78\n",
      "       8. DEATH       0.85      0.70      0.77       376\n",
      "\n",
      "       accuracy                           0.74    459219\n",
      "      macro avg       0.78      0.49      0.53    459219\n",
      "   weighted avg       0.72      0.74      0.71    459219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1229  1088    37   130    10     0     0     1]\n",
      " [  396 55856   313  1532   115     0     0     4]\n",
      " [   20  8011  1122  4002   624     2     0     0]\n",
      " [   15  6896   679 20389  1703     6     0    14]\n",
      " [    2   360   164  3427  5703     0     0     0]\n",
      " [    0     3     7   718   110     4     0     0]\n",
      " [    0     0     0    16     3     0     0     0]\n",
      " [    3    10     1    49     1     0     0    30]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   1. CANCELLED       0.74      0.49      0.59      2495\n",
      "    2. NON-COMP       0.77      0.96      0.86     58216\n",
      "    3. MED ONLY       0.48      0.08      0.14     13781\n",
      "   4. TEMPORARY       0.67      0.69      0.68     29702\n",
      "5. PPD SCH LOSS       0.69      0.59      0.64      9656\n",
      "     6. PPD NSL       0.33      0.00      0.01       842\n",
      "         7. PTD       0.00      0.00      0.00        19\n",
      "       8. DEATH       0.61      0.32      0.42        94\n",
      "\n",
      "       accuracy                           0.73    114805\n",
      "      macro avg       0.54      0.39      0.42    114805\n",
      "   weighted avg       0.70      0.73      0.69    114805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:salmon\"> 3. Test Predictions </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers(X_train_to_preprocess)\n",
    "X_train_to_preprocess, test_df = apply_frequency_encoding(X_train_to_preprocess, test_df)\n",
    "NA_imputer(X_train_to_preprocess, test_df)\n",
    "create_new_features(X_train_to_preprocess, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numerical_features]  = scaler.transform(test_df[numerical_features])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_df)\n",
    "y_test_pred = y_test_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = np.array([class_mapping[i] for i in y_test_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'Claim Identifier': test_id,\n",
    "    'Claim Injury Type': y_test_final\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    version = version_control()\n",
    "    submission_df.to_csv(f'./submissions/Group49_Version{version:02}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
