{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bcee083-80e0-4a06-860a-de8351bfa268",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Project</center>\n",
    "\n",
    "** **\n",
    "## <center>*06 - Predictive Model*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "The members of the `team` are:\n",
    "- Ana Farinha - 20211514\n",
    "- Francisco Capontes - 20211692\n",
    "- Sofia Gomes - 20240848\n",
    "- Rui Louren√ßo - 2021639"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9fbb0-e5cd-4b8b-9b43-917aa2930313",
   "metadata": {},
   "source": [
    "\n",
    "| Model              | Best Parameters  | Feature Selection | Average Validation Macro F1 Score | Validation Macro F1-Score |\n",
    "|--------------------|--------------------------------------|---|---------------|---------------|\n",
    "| CatBoostClassifier | `{\"iterations\": 1000, \"learning_rate\": 0.11, \"depth\": 6, \"l2_leaf_reg\": 5, bagging_temperature\": 0.4}`| `None` | `0.41` | `0.42` |\n",
    "| XGBoostClassifier  | `{\"n_estimators\": 200, \"learning_rate\": 0.2, \"max_depth\": 7, \"subsample\": 0.9, \"colsample_bytree\": 0.9, \"gamma\": 0.3}`| `None` | `0.42`|`0.42`|\n",
    "| Decision Trees     | `{\"min_samples_split\": 10, \"min_samples_leaf\": 4, \"max_depth\": 20, \"criterion\": \"entropy\"}`| `Essential Features` | `0.33`| `0.34`|\n",
    "| Naive Bayes        | `Default Parameters`| `Essential Features` | `0.24`| `0.23`|\n",
    "| StackEnsemble      | `CatBoost Config 1, XGBoost Config 1, Decision Trees, Default Parameters`     | `Essential Features` | `0.30`| `0.31`|\n",
    "| VotingEnsemble     | `CatBoost Config 2, XGBoost Config 2, Decision Trees, Default Parameters` | `None` | `0.41`| `0.42`|\n",
    "| XGBoostClassifier With kfold | `{\"n_estimators\": 200, \"learning_rate\": 0.2, \"max_depth\": 7, \"subsample\": 0.9, \"colsample_bytree\": 0.9, \"gamma\": 0.3}`| `None` | `0.44`|`0.45`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383a440b-6c2e-4b59-b80b-f04579bcd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falar q vamos usar CatBoost ou XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d971ae-afd5-44af-bfb1-d68601957cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#make the split here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "from utils_feature_selection import check_performace\n",
    "from utils_dicts import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_state=68+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78208177-053c-41bd-a7b1-bbef43db1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "train_df = pd.read_csv('preprocessed_data/train_data.csv', index_col=\"Claim Identifier\")\n",
    "test_df = pd.read_csv('./preprocessed_data/test_data.csv', index_col = 'Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c75069-661f-4b8d-9160-ccae48dfc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Selection: essential_features, reduced_features or []\n",
    "feature_selection = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd661e-4eeb-4d84-a5c0-151ff7070d37",
   "metadata": {},
   "source": [
    "Define y as a target \"Claim Injury Type Encoded\" and X with all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2232728-35e4-4e12-8ec3-30483b640b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop([\"Claim Injury Type Encoded\"], axis = 1)\n",
    "y = train_df[\"Claim Injury Type Encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e040a1ea-e2fb-4b9e-a495-21f826772fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"max_depth\": 7,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"gamma\": 0.3,\n",
    "    \"random_state\": random_state\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84430fe0-83de-4730-8e57-e56cf1b44143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0:'1. CANCELLED', \n",
    "    1:'2. NON-COMP',\n",
    "    2:'3. MED ONLY', \n",
    "    3:'4. TEMPORARY',\n",
    "    4:'5. PPD SCH LOSS', \n",
    "    5:'6. PPD NSL', \n",
    "    6:'7. PTD', \n",
    "    7:'8. DEATH'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f3f980-124a-4321-8c6b-2ca754dd6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=6, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aeaff0-c520-4de4-a2c1-f2475506b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1...\n",
      "\n",
      "Fold 1 train F1 score: 0.7488\n",
      "Fold 1 validation F1 score: 0.4336\n",
      "------------------------------\n",
      "Processing Fold 2...\n",
      "\n",
      "Fold 2 train F1 score: 0.7505\n",
      "Fold 2 validation F1 score: 0.4446\n",
      "------------------------------\n",
      "Processing Fold 3...\n",
      "\n",
      "Fold 3 train F1 score: 0.7552\n",
      "Fold 3 validation F1 score: 0.4567\n",
      "------------------------------\n",
      "Processing Fold 4...\n",
      "\n",
      "Fold 4 train F1 score: 0.7537\n",
      "Fold 4 validation F1 score: 0.4405\n",
      "------------------------------\n",
      "Processing Fold 5...\n",
      "\n",
      "Fold 5 train F1 score: 0.7581\n",
      "Fold 5 validation F1 score: 0.4526\n",
      "------------------------------\n",
      "Processing Fold 6...\n",
      "\n",
      "Fold 6 train F1 score: 0.7549\n",
      "Fold 6 validation F1 score: 0.4467\n",
      "------------------------------\n",
      "Average Train F1 score: 0.7535329372930706\n",
      "Average Validation F1 score: 0.4457753473919755\n"
     ]
    }
   ],
   "source": [
    "test_preds = np.zeros((len(test_df), len(class_mapping)))\n",
    "avg_train = []\n",
    "avg_val = []\n",
    "models = {} # save models\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "    print(f\"Processing Fold {fold + 1}...\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    test_temp =test_df.copy()\n",
    "    train_temp=X_train.copy()\n",
    "    \n",
    "    # Preprocess X_train and X_Val\n",
    "    remove_outliers(X_train)\n",
    "    X_train, X_val = apply_frequency_encoding(X_train, X_val, True, fold=fold)\n",
    "    NA_imputer(X_train,X_val, True, fold=fold)\n",
    "    create_new_features(X_train,X_val)\n",
    "    \n",
    "    # Preprocess Test_df\n",
    "    remove_outliers(train_temp)\n",
    "    train_temp, test_temp = apply_frequency_encoding(train_temp, test_temp)\n",
    "    NA_imputer(train_temp, test_temp)\n",
    "    create_new_features(train_temp, test_temp)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train[numerical_features])\n",
    "    # Save Scaler\n",
    "    joblib.dump(scaler, f'./OthersPipeline/Scaler_{fold}.pkl')\n",
    "    X_train[numerical_features]  = scaler.transform(X_train[numerical_features])\n",
    "    X_val[numerical_features]  = scaler.transform(X_val[numerical_features])  \n",
    "    test_temp[numerical_features]  = scaler.transform(test_temp[numerical_features])  \n",
    "\n",
    "    drop_list = [\"Average Weekly Wage\"]\n",
    "    if feature_selection != []:\n",
    "        for col in X_train.columns:\n",
    "            if col not in feature_selection:\n",
    "                drop_list.append(col)\n",
    "        \n",
    "    # Train model\n",
    "    model = XGBClassifier(\n",
    "            n_estimators=config[\"n_estimators\"],        \n",
    "            learning_rate=config[\"learning_rate\"],      \n",
    "            max_depth=config[\"max_depth\"],                          \n",
    "            subsample=config[\"subsample\"],              \n",
    "            colsample_bytree=config[\"colsample_bytree\"],\n",
    "            gamma=config[\"gamma\"],                     \n",
    "            objective=\"multi:softmax\",                  \n",
    "            num_class=8,                                \n",
    "            eval_metric=\"merror\",   \n",
    "            random_state=config[\"random_state\"],                                      \n",
    "            verbosity=0                                 \n",
    "        )\n",
    "    model.fit(X_train,y_train)\n",
    "    # Save Model\n",
    "    joblib.dump(model, f'./OpenEnded/Model_{fold}.pkl')\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_val = model.predict(X_val)\n",
    "    \n",
    "    f1_train = f1_score(y_train, pred_train, average='macro')\n",
    "    f1_val = f1_score(y_val, pred_val, average='macro')\n",
    "\n",
    "    avg_train.append(f1_train)\n",
    "    avg_val.append(f1_val)\n",
    "\n",
    "    print(f\"Fold {fold + 1} train F1 score: {f1_train:.4f}\")\n",
    "    print(f\"Fold {fold + 1} validation F1 score: {f1_val:.4f}\")\n",
    "    print(f\"------------------------------\")\n",
    "    \n",
    "    test_preds += model.predict_proba(test_temp)\n",
    "\n",
    "    models[f\"Fold {fold +1}\"] = model\n",
    "\n",
    "print(f\"Average Train F1 score: {sum(avg_train)/len(avg_train)}\")\n",
    "print(f\"Average Validation F1 score: {sum(avg_val)/len(avg_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f8f088-4797-44d6-a3d4-f654ef8e87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c0f48b-8031-4a2e-a948-a5177ff04a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_preds = np.argmax(test_preds / kf.get_n_splits(), axis=1)\n",
    "submission_df = pd.DataFrame({\n",
    "    'Claim Identifier': test_id,\n",
    "    'Claim Injury Type': final_test_preds\n",
    "})\n",
    "submission_df[\"Claim Injury Type\"] = submission_df[\"Claim Injury Type\"].replace(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "410e922e-c323-4bf9-81be-1606a606da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Best Score V27\n",
    "    version = version_control()\n",
    "    submission_df.to_csv(f'./submissions/Group49_Version{version:02}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b072bd5a-830a-4497-8d61-ec1d919c3b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fold 1': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...),\n",
       " 'Fold 2': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...),\n",
       " 'Fold 3': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...),\n",
       " 'Fold 4': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...),\n",
       " 'Fold 5': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...),\n",
       " 'Fold 6': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='merror',\n",
       "               feature_types=None, gamma=0.3, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "               n_jobs=None, num_class=8, num_parallel_tree=None, ...)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
