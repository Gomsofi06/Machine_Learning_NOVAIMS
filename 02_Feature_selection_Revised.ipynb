{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Project</center>\n",
    "\n",
    "** **\n",
    "## <center>*02 - Feature Selection*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "The members of the `team` are:\n",
    "- Ana Farinha - 20211514\n",
    "- Francisco Capontes - 20211692\n",
    "- Sofia Gomes - 20240848\n",
    "- Rui Louren√ßo - 2021639\n",
    "\n",
    "## <span style=\"color:salmon\"> Table of Contents </span>\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "1. [Filter Methods](#1-filter-methods)<br>  \n",
    "    1.1 [Univariate Variables](#11-univariate-variables)<br>  \n",
    "    1.2 [Correlation Indices](#12-correlation-indices)<br>    \n",
    "    1.3 [Chi-Squared](#13-chi-squared)<br><br>     \n",
    "2. [Wrapper Methods](#2-wrapper-methods)<br>    \n",
    "    2.1 [Logistic Regression](#21-logistic-regression)<br>    \n",
    "    2.2 [Support Vector Machine](#22-support-vector-machine)<br><br>      \n",
    "3. [Embedded Methods](#3-embedded-methods)<br>     \n",
    "    3.1 [LassoCV](#31-lassocv)<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Sklearn packages\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# embedded methods\n",
    "from sklearn.linear_model import LassoCV\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import *\n",
    "from utils_feature_selection import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No train temos de input:\n",
    "- Average Weekly Wage\n",
    "- Age at Injury\n",
    "\n",
    "- Based on the new Age at Injury calcular o Birth Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Input `Birth Year`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train_df = pd.read_csv('preprocessed_data/train_data.csv', index_col=\"Claim Identifier\")\n",
    "#test_df =  pd.read_csv('preprocessed_data/test_data.csv', index_col=\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'Age at Injury','Average Weekly Wage','Birth Year','IME-4 Count',\n",
    "    'WCIO Cause of Injury Code','WCIO Nature of Injury Code','WCIO Part Of Body Code',\n",
    "    'Number of Dependents','Days_to_First_Hearing','Days_to_C2','Days_to_C3',\n",
    "    'Enc County of Injury', 'Enc District Name','Enc Industry Code',\n",
    "    'Medical Fee Region_I','Medical Fee Region_II','Medical Fee Region_III','Medical Fee Region_IV',\n",
    "    'Enc WCIO Cause of Injury Code',\n",
    "    'Nature_Injury_Code_Hash_0','Nature_Injury_Code_Hash_1','Nature_Injury_Code_Hash_2',\n",
    "    'Nature_Injury_Code_Hash_3','Nature_Injury_Code_Hash_4','Nature_Injury_Code_Hash_5',\n",
    "    'Nature_Injury_Code_Hash_6','Nature_Injury_Code_Hash_7','Nature_Injury_Code_Hash_8',\n",
    "    'Nature_Injury_Code_Hash_9','Nature_Injury_Code_Hash_10','Nature_Injury_Code_Hash_11',\n",
    "    'Nature_Injury_Code_Hash_12','Nature_Injury_Code_Hash_13','Nature_Injury_Code_Hash_14',\n",
    "    'Nature_Injury_Code_Hash_15','Nature_Injury_Code_Hash_16','Nature_Injury_Code_Hash_17',\n",
    "    'Nature_Injury_Code_Hash_18','Nature_Injury_Code_Hash_19',\n",
    "    'Zip_Code_Hash_0','Zip_Code_Hash_1',\n",
    "    'Zip_Code_Hash_2','Zip_Code_Hash_3','Zip_Code_Hash_4',\n",
    "    'Zip_Code_Hash_5','Zip_Code_Hash_6','Zip_Code_Hash_7',\n",
    "    'Zip_Code_Hash_8','Zip_Code_Hash_9','Zip_Code_Hash_10',\n",
    "    'Zip_Code_Hash_11','Zip_Code_Hash_12','Zip_Code_Hash_13',\n",
    "    'Zip_Code_Hash_14','Zip_Code_Hash_15','Zip_Code_Hash_16',\n",
    "    'Zip_Code_Hash_17','Zip_Code_Hash_18','Zip_Code_Hash_19',\n",
    "    'Claim Injury Type Encoded',\n",
    "    'Accident_Season_Sin','Accident_Season_Cos'\n",
    "]\n",
    "categorical_features = [\n",
    "    'Known Accident Date','Known Assembly Date','Known C-2 Date','Known C-3 Date',\n",
    "    'Known First Hearing Date','Known Age at Injury','Known Birth Year','Accident Date_Year',\n",
    "    'Accident Date_Month','Accident Date_Day','Accident Date_DayOfWeek','Assembly Date_Year',\n",
    "    'Assembly Date_Month','Assembly Date_Day','Assembly Date_DayOfWeek',\n",
    "    'C-2 Date_Year','C-2 Date_Month','C-2 Date_Day','C-2 Date_DayOfWeek',\n",
    "    'C-3 Date_Year','C-3 Date_Month','C-3 Date_Day', 'C-3 Date_DayOfWeek',\n",
    "    'First Hearing Date_Year','First Hearing Date_Month','First Hearing Date_Day','First Hearing Date_DayOfWeek',\n",
    "    'Holiday_Accident','Weekend_Accident', 'Risk_Level','Gender_F','Gender_M'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop([\"Claim Injury Type Encoded\"], axis = 1)\n",
    "y = train_df[\"Claim Injury Type Encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.25, stratify = y, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Age at Injury, Birth Year and Average Weekly Wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_BY = X_train[\"Birth Year\"]\n",
    "X_val_BY = X_val[\"Birth Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_AD = X_train[\"Accident Date\"]\n",
    "#X_val_AD = X_val[\"Accident Date\"]\n",
    "\n",
    "#X_train.drop(\"Accident Date\",axis=1,inplace=True)\n",
    "#X_val.drop(\"Accident Date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = KNNImputer(n_neighbors=3)\n",
    "#X_train = imputer.fit_transform(X_train)\n",
    "#X_val = imputer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_impute = [\"Age at Injury\",\"Average Weekly Wage\"]\n",
    "percent_missing = X_train[to_impute].isnull().mean()\n",
    "imputation_value = percent_missing / ((1 / 0.97) - 1)\n",
    "for col in to_impute:\n",
    "        X_train[col].fillna(imputation_value[col], inplace=True)\n",
    "        X_val[col].fillna(imputation_value[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Birth Year\"] = X_train_BY\n",
    "X_val[\"Birth Year\"] = X_val_BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m condition \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirth Year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m&\u001b[39m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge at Injury\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna() \u001b[38;5;241m&\u001b[39m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccident Date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Replace missing 'Birth Year' with the difference between 'Accident Date' year and 'Age at Injury'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train\u001b[38;5;241m.\u001b[39mloc[condition, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirth Year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccident Date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccident Date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[condition, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge at Injury\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Filter the rows where 'Birth Year' is NaN, but 'Age at Injury' and 'Accident Date' are not NaN in the test dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m condition \u001b[38;5;241m=\u001b[39m X_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirth Year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m&\u001b[39m X_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge at Injury\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna() \u001b[38;5;241m&\u001b[39m X_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccident Date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()\n",
      "File \u001b[1;32m~\\Desktop\\Master Projects\\ML Project\\Machine_Learning_NOVAIMS\\env\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Master Projects\\ML Project\\Machine_Learning_NOVAIMS\\env\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\Desktop\\Master Projects\\ML Project\\Machine_Learning_NOVAIMS\\env\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Filter the rows where 'Birth Year' is NaN, but 'Age at Injury' and 'Accident Date' are not NaN\n",
    "condition = X_train['Birth Year'].isna() & X_train['Age at Injury'].notna() & X_train[\"Accident Date\"].notna()\n",
    "# Replace missing 'Birth Year' with the difference between 'Accident Date' year and 'Age at Injury'\n",
    "X_train.loc[condition, 'Birth Year'] = X_train[\"Accident Date\"].dt.year - X_train[\"Accident Date\"].loc[condition, 'Age at Injury']\n",
    "\n",
    "# Filter the rows where 'Birth Year' is NaN, but 'Age at Injury' and 'Accident Date' are not NaN in the test dataset\n",
    "condition = X_val['Birth Year'].isna() & X_val['Age at Injury'].notna() & X_val[\"Accident Date\"].notna()\n",
    "# Replace missing 'Birth Year' with the difference between 'Accident Date' year and 'Age at Injury' where the condition is true\n",
    "X_val.loc[condition, 'Birth Year'] = X_test[\"Accident Date\"].dt.year - X_val[\"Accident Date\"].loc[condition, 'Age at Injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('Accident Date',axis=1,inplace=True)\n",
    "X_val.drop('Accident Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Average Weekly Wage*\n",
    "\n",
    "Relative Wage Compared to Median Wage:<br>\n",
    "Calculate whether the injured worker‚Äôs wage is above or below the median wage for the dataset, it's potentially reflecting job type or socioeconomic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_wage = X_train['Average Weekly Wage'].median()\n",
    "X_train['Relative_Wage'] = np.where(X_train['Average Weekly Wage'] > median_wage, 1,0) #('Above Median', 'Below Median')\n",
    "X_val['Relative_Wage'] = np.where(X_val['Average Weekly Wage'] > median_wage, 1,0) #('Above Median', 'Below Median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Financial Impact*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_impact(X_train)\n",
    "financial_impact(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Binning:__ Group ages into categories like \"young\" or \"senior\" if such categories might capture different risk profiles.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 25, 40, 55, 70, 100]\n",
    "age_labels = [0,1,2,3,4] #['Young', 'Mid-Age', 'Experienced', 'Senior', 'Elderly']\n",
    "X_train['Age_Group'] = pd.cut(X_train['Age at Injury'], bins=age_bins, labels=age_labels)\n",
    "X_val['Age_Group'] = pd.cut(X_val['Age at Injury'], bins=age_bins, labels=age_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = StandardScaler()\n",
    "X_train[numerical_features] = mm.fit_transform(X_train[numerical_features])\n",
    "X_val[numerical_features] = mm.transform(X_val[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Univariate variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Corr Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial correlation matrix with the respective values\n",
    "corr_matrix = X_train[numerical_features].corr()\n",
    "\n",
    "mask = np.tri(*corr_matrix.shape, k=0, dtype=bool)\n",
    "# Keeps values where mask is True\n",
    "corr_matrix = corr_matrix.where(mask)\n",
    "\n",
    "# defines the figure size\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# heatmap of the initial correlation matrix\n",
    "l = sns.heatmap(corr_matrix, square=True, annot=True, fmt=\".2f\", vmax=1, vmin=-1, cmap='RdBu', ax=ax)\n",
    "plt.title('Correlation Between Variables', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*XGBoosted RFE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_XGB = feature_selection_RFE(X_train,y_train,n_features,model=XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CatBoosted RFE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, cat_features=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_CB = feature_selection_RFE(X_train,y_train,n_features,model=CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LogisticRegression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LR = feature_selection_RFE(X_train,y_train,n_features,model=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lasso*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_Lasso(X_train_temp[numerical_features],y_train_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Chi-squared test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features+binary_features:\n",
    "    TestIndependence(X_train[col],y_train,col,alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Numerical Data\n",
    "\n",
    "| Predictor | Spearman | RFE XGB| RFE DT | Lasso | What to do? (One possible way to \"solve\") |\n",
    "| --- | --- | --- | --- |--- |---|\n",
    "| Age at Injury | Keep? | Discard | Discard |Discard | Discard |\n",
    "| IME-4 Count | Keep | Keep | Keep |Keep| Include in the model |\n",
    "| WCIO Cause of Injury Code | Keep| Keep | Discard | Discard | Try with and without |\n",
    "| WCIO Nature of Injury Code | Keep | Keep | Keep | Discard | Include in the model |\n",
    "| WCIO Part Of Body Code | Keep | Keep | Discard | Discard | Try with and without |\n",
    "| Number of Dependents | Keep | Discard | Discard | Discard | Discard |\n",
    "| Years Past Accident | Keep | Keep | Discard | Keep | Include in the model |\n",
    "| Assembly Years past Accident | Discard |Keep |Discart | Keep |  Discard | # Years Past Accident\n",
    "| Industry Code | Keep |Keep |Discard | Keep |   Include in the model |\n",
    "| Birth Year | Keep? |Keep |Discard | Keep |  Try with and without |\n",
    "| Average Weekly Wage | Keep |Keep |Keep | Keep |  Include in the model |\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Categorical Data\n",
    "\n",
    "| Predictor | Chi-Square |\n",
    "| --- | --- |\n",
    "| Carrier Name | Keep |  \n",
    "| Carrier Type | Keep |\n",
    "| County of Injury| Keep|\n",
    "| District Name| Keep|\n",
    "| Gender | Keep |\n",
    "| Medical Fee Region | Keep |\n",
    "| Attorney/Representative | Keep |\n",
    "| COVID-19 Indicator | Keep |\n",
    "| First Hearing Date Occurred | Keep |\n",
    "| C-2 Date Occurred | Keep |\n",
    "| C-3 Date Occurred| Keep |\n",
    "| Birth Year Occurred | Keep |\n",
    "| Age at Injury Occurred | Keep |\n",
    "| Accident Date Occurred | KEEP |\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0:'1. CANCELLED', \n",
    "    1:'2. NON-COMP',\n",
    "    2:'3. MED ONLY', \n",
    "    3:'4. TEMPORARY',\n",
    "    4:'5. PPD SCH LOSS', \n",
    "    5:'6. PPD NSL', \n",
    "    6:'7. PTD', \n",
    "    7:'8. DEATH'\n",
    "}\n",
    "test_encoder = LabelEncoder()\n",
    "test_encoder.classes_ = np.array(list(class_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
